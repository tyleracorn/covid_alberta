{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class albertaC19_webscraper():\n",
    "    def __init__(self, covid_url:str='https://covid19stats.alberta.ca/', outputfolder:str='data'):\n",
    "        '''\n",
    "        using requests and BeautfulSoup4 scrape updated covid data from the ablerta website\n",
    "        save the outputs into a outputfolder\n",
    "        '''\n",
    "        self.covid_url = covid_url\n",
    "        self.outputfolder = Path(outputfolder)\n",
    "        if not self.outputfolder.is_dir(): self.outputfolder.mkdir()\n",
    "\n",
    "        self.page = requests.get(self.covid_url)\n",
    "        self.soup = BeautifulSoup(self.page.content, 'html.parser')\n",
    "\n",
    "    def scrape_albertaTotals(self, output_filename:str='albertaTotalData', fltypes=['csv', 'json'],\n",
    "                             return_dataframe:bool=False):\n",
    "        '''scrape the total case counts in alberta and save the data to the output folder\n",
    "\n",
    "        Parameters:\n",
    "            output_filename:str\n",
    "                filename without the file ending\n",
    "            fltypes:[list or str]\n",
    "                will save out either csv, json or both filetypes\n",
    "            return_dataframe:bool\n",
    "                will return either the dataframes or a true/false on write success\n",
    "        '''\n",
    "        results = self.soup.find(id='case-counts')\n",
    "        caseCountResults = results.find_all('script')\n",
    "\n",
    "        # Scrape the data\n",
    "        caseCountCum = json.loads(caseCountResults[0].string)\n",
    "        caseCountByDat = json.loads(caseCountResults[2].string)\n",
    "        albertaTotalData = {'cumulative': {'date': caseCountCum['x']['data'][0]['x'],\n",
    "                                           'cum_cases': caseCountCum['x']['data'][0]['y']},\n",
    "                            'byDay': {'date': caseCountByDat['x']['data'][0]['x'],\n",
    "                                      'new_cases': caseCountByDat['x']['data'][0]['y']}\n",
    "                            }\n",
    "        # Write out or Return the data\n",
    "        write_sucess = False\n",
    "        if 'json' in fltypes:\n",
    "            flpath = self.outputfolder.joinpath(output_filename).with_suffix('.json')\n",
    "            aTotal = json.dumps(albertaTotalData)\n",
    "            with open(flpath, \"w\") as fl:\n",
    "                fl.write(aTotal)\n",
    "            write_sucess = True\n",
    "        if 'csv' in fltypes or return_dataframe:\n",
    "            flpath = self.outputfolder.joinpath(output_filename).with_suffix('.csv')\n",
    "            abTotalCum = pd.DataFrame(data=albertaTotalData['cumulative']['cum_cases'],\n",
    "                                      index=albertaTotalData['cumulative']['date'],\n",
    "                                      columns=['cum_cases'])\n",
    "            abTotalCum.index = pd.to_datetime(abTotalCum.index)\n",
    "\n",
    "            abTotalNCases = pd.DataFrame(data=albertaTotalData['byDay']['new_cases'],\n",
    "                                         index=albertaTotalData['byDay']['date'],\n",
    "                                         columns=['new_cases'])\n",
    "            abTotalNCases.index = pd.to_datetime(abTotalNCases.index)\n",
    "            abTotal = abTotalNCases.join(abTotalCum)\n",
    "\n",
    "            if 'csv' in fltypes:\n",
    "                abTotal.to_csv(flpath)\n",
    "            if return_dataframe:\n",
    "                return abTotal\n",
    "            write_sucess = True\n",
    "        return write_sucess\n",
    "\n",
    "    def scrape_albertaRegions(self, output_filename:str='albertaRegionData', fltypes=['csv', 'json'],\n",
    "                              return_dataframe:bool=False):\n",
    "        '''scrape the total case counts in alberta by region and save the data\n",
    "        to the output folder\n",
    "\n",
    "        Parameters:\n",
    "            output_filename:str\n",
    "                filename without the file ending\n",
    "            fltypes:[list or str]\n",
    "                will save out either csv, json or both filetypes\n",
    "            return_dataframe:bool\n",
    "                will return either the dataframes or a true/false on write success\n",
    "        '''\n",
    "        results = self.soup.find(id='geospatial')\n",
    "        regionCaseCountResults = results.find_all('script')\n",
    "        regionCCDict = json.loads(regionCaseCountResults[0].string)['x']\n",
    "\n",
    "        zoneLen = len(regionCCDict['data'])\n",
    "        albertaRegionData = dict()\n",
    "        for idx in range (zoneLen):\n",
    "            zoneName = regionCCDict['data'][idx]['name']\n",
    "            albertaRegionData[zoneName] = {'date':regionCCDict['data'][idx]['x'],\n",
    "                                           'new_cases':regionCCDict['data'][idx]['y']}\n",
    "        write_sucess = False\n",
    "        # Write out the data\n",
    "        if 'json' in fltypes:\n",
    "            flpath = self.outputfolder.joinpath(output_filename).with_suffix('.json')\n",
    "            aRegion = json.dumps(albertaRegionData)\n",
    "            with open(flpath, \"w\") as fl:\n",
    "                fl.write(aRegion)\n",
    "            write_sucess = True\n",
    "        if 'csv' in fltypes or return_dataframe:\n",
    "            flpath = self.outputfolder.joinpath(output_filename).with_suffix('.csv')\n",
    "            abRegions = list()\n",
    "            for idx, key in enumerate(albertaRegionData.keys()):\n",
    "                if 'Zone' in key:\n",
    "                    zone = key.strip(' Zone')\n",
    "                else:\n",
    "                    zone = key\n",
    "                column = f'{zone}_newCases'\n",
    "                abRegions.append(pd.DataFrame(data=albertaRegionData[key]['new_cases'],\n",
    "                                              index=albertaRegionData[key]['date'],\n",
    "                                              columns=[column]))\n",
    "\n",
    "            abRegionsDF = abRegions[0].join(abRegions[1:])\n",
    "            abRegionsDF.index = pd.to_datetime(abRegionsDF.index)\n",
    "            abRegionsDF.fillna(0, inplace=True)\n",
    "            abRegionsDF = abRegionsDF.astype(int)\n",
    "\n",
    "            if 'csv' in fltypes:\n",
    "                abRegionsDF.to_csv(flpath)\n",
    "            if return_dataframe:\n",
    "                return abRegionsDF\n",
    "            write_sucess = True\n",
    "        return write_sucess\n",
    "\n",
    "    def scrape_albertaTesting(self, output_filename:str='albertaTestingData', fltypes=['csv', 'json'],\n",
    "                              return_dataframe:bool=False):\n",
    "        '''scrape the testing counts by date in alberta and save the data\n",
    "        to the output folder\n",
    "\n",
    "        Parameters:\n",
    "            output_filename:str\n",
    "                filename without the file ending\n",
    "            fltypes:[list or str]\n",
    "                will save out either csv, json or both filetypes\n",
    "            return_dataframe:bool\n",
    "                will return either the dataframes or a true/false on write success\n",
    "        '''\n",
    "        results = self.soup.find(id='laboratory-testing')\n",
    "        testingResults = results.find_all('script')\n",
    "\n",
    "        # Scrape the data\n",
    "        testingDict = json.loads(testingResults[0].string)['x']\n",
    "        testingDict.keys()\n",
    "        albertaTestingData = dict()\n",
    "        for idx in range(len(testingDict['data'])):\n",
    "            albertaTestingData[testingDict['data'][idx]['name']] = {'date': testingDict['data'][idx]['x'],\n",
    "                                                                    'n_tests': testingDict['data'][idx]['y']}\n",
    "        # Write out the data\n",
    "        write_sucess = False\n",
    "        if 'json' in fltypes:\n",
    "            flpath = self.outputfolder.joinpath(output_filename).with_suffix('.json')\n",
    "            aTest = json.dumps(albertaTestingData)\n",
    "            with open(flpath, \"w\") as fl:\n",
    "                fl.write(aTest)\n",
    "            write_sucess = True\n",
    "        if 'csv' in fltypes or return_dataframe:\n",
    "            flpath = self.outputfolder.joinpath(output_filename).with_suffix('.csv')\n",
    "            abTesting = list()\n",
    "            for idx, key in enumerate(albertaTestingData.keys()):\n",
    "                column = f'{key}_newTests'\n",
    "                abTesting.append(pd.DataFrame(data=albertaTestingData[key]['n_tests'],\n",
    "                                              index=albertaTestingData[key]['date'],\n",
    "                                              columns=[column]))\n",
    "            abTestsDF = abTesting[0].join(abTesting[1:])\n",
    "            abTestsDF.index = pd.to_datetime(abTestsDF.index)\n",
    "            abTestsDF.fillna(0, inplace=True)\n",
    "            abTestsDF = abTestsDF.astype(int)\n",
    "\n",
    "            if 'csv' in fltypes:\n",
    "                abTestsDF.to_csv(flpath)\n",
    "            if return_dataframe:\n",
    "                return abTestsDF\n",
    "            write_sucess = True\n",
    "        return write_sucess\n",
    "\n",
    "    def scrape_all(self, totalfl:str='albertaTotalData', regionsfl:str='albertaRegionData',\n",
    "                   testfl:str='albertaTestingData', fltypes=['csv', 'json'],\n",
    "                   return_dataframes:bool=False):\n",
    "        '''scrape the total alberta covid-19 case counts, the covid-19 case counts by\n",
    "        region and the testing data from the alberta covid-19 website\n",
    "\n",
    "        Parameters:\n",
    "            output_filename:str\n",
    "                filename without the file ending\n",
    "            fltypes:[list or str]\n",
    "                will save out either csv, json or both filetypes\n",
    "            return_dataframe:bool\n",
    "                will return either the dataframes or a true/false on write success\n",
    "        Returns:\n",
    "            totals, regions, testing\n",
    "\n",
    "        '''\n",
    "        totals = self.scrape_albertaTotals(totalfl, fltypes, return_dataframes)\n",
    "        regions = self.scrape_albertaRegions(regionsfl, fltypes, return_dataframes)\n",
    "        testing = self.scrape_albertaTesting(testfl, fltypes, return_dataframes)\n",
    "        return totals, regions, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "abC19scaper = albertaC19_webscraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abC19scaper.scrape_albertaRegions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abC19scaper.scrape_albertaTesting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abC19scaper.scrape_albertaTotals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abC19scaper.scrape_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
